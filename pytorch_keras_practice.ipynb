{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-keras-practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LL-Jan/Kaggle/blob/main/pytorch_keras_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9J4JxSL6flE",
        "outputId": "54d0fa0a-b816-4748-9c62-44715eef96d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgQf1mfi6flG",
        "scrolled": true
      },
      "source": [
        "!pip install segmentation-models-pytorch==0.1.3\n",
        "!pip install albumentations==0.5.2 \n",
        "!pip install netron\n",
        "!pip install plotly==4.14.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVCKXF5E6flH"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import json \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# pd.set_option(\"display.max_rows\", 101)\n",
        "# pd.set_option(\"expand_frame_repr\", True)\n",
        "# pd.set_option(\"mode.use_inf_as_na\", True)\n",
        "# pd.options.plotting.backend = 'plotly'\n",
        "\n",
        "from random import shuffle\n",
        "\n",
        "import time\n",
        "t0 = time.time()\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.style.use('dark_background')\n",
        "# %matplotlib widget\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go \n",
        "# template = 'plotly_dark'\n",
        "template = 'plotly'\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset \n",
        "from torchvision.datasets import ImageFolder \n",
        "from torchvision import transforms as tfs \n",
        "import torchvision.models as models \n",
        "\n",
        "import albumentations as amt\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "import netron"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPLBJE9a8pL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07aa4b9-257c-42ae-cf6f-523d6ad9ce79"
      },
      "source": [
        "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 'Tesla T4')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Vu4ax06flI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6efe1c0-eedc-4a3d-8727-4f1771dffed5"
      },
      "source": [
        "random_state = 618\n",
        "torch.manual_seed(random_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa2d7339a70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNP38BZv6flI"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP-w45TaGXeV"
      },
      "source": [
        "nb_path = \"/content/drive/MyDrive/Colab/Kaggle/severstal-steel-defect-detection\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YneVX2uf6flI"
      },
      "source": [
        "train = pd.read_csv(os.path.join(nb_path, \"train.csv\"))\n",
        "# train = pd.read_csv(\"../input/severstal-steel-defect-detection/train.csv\")\n",
        "# train = pd.read_csv(\"./severstal-steel-defect-detection/train.csv\")                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrRnPMYY6flJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a85b908b-062a-4eac-93bb-c90b36ab08a4"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0007a71bf.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000a4bcdd.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>37607 3 37858 8 38108 14 38359 20 38610 25 388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000f6bf48.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0014fce06.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>229501 11 229741 33 229981 55 230221 77 230468...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ImageId  ClassId                                      EncodedPixels\n",
              "0  0002cc93b.jpg        1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
              "1  0007a71bf.jpg        3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
              "2  000a4bcdd.jpg        1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
              "3  000f6bf48.jpg        4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
              "4  0014fce06.jpg        3  229501 11 229741 33 229981 55 230221 77 230468..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR3Ztnaf6flJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea4dbb6-4347-4522-ae8f-40b0b006f66c"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7095 entries, 0 to 7094\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   ImageId        7095 non-null   object\n",
            " 1   ClassId        7095 non-null   int64 \n",
            " 2   EncodedPixels  7095 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 166.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWiBDOgv6flJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebd0367-a2c8-4847-93d7-2e220d0e4e04"
      },
      "source": [
        "train['ImageId'].nunique(), train['EncodedPixels'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6666, (4, array([1, 3, 4, 2])), 7095)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HJtmm8FOM-A"
      },
      "source": [
        "train['ClassId'].nunique(), train['ClassId'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cCpl1vH6flK",
        "outputId": "b412a4ef-332a-492b-93ab-cc972bc2683c"
      },
      "source": [
        "train_image_path = os.path.join(nb_path, \"train_images\")\n",
        "test_image_path = os.path.join(nb_path, \"test_images\")\n",
        "\n",
        "# train_image_path = \"../input/severstal-steel-defect-detection/train_images/\"\n",
        "# test_image_path = \"../input/severstal-steel-defect-detection/test_images/\"\n",
        "\n",
        "# train_image_path = \"./severstal-steel-defect-detection/train_images/\"\n",
        "# test_image_path = \"./severstal-steel-defect-detection/test_images/\"\n",
        "\n",
        "print(f\"{len(os.listdir(train_image_path))} images in training set\")\n",
        "print(f\"{len(os.listdir(test_image_path))} images in test set\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13011 images in training set\n",
            "5702 images in test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4ks2mWs6flK"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-lt8Ute6flK"
      },
      "source": [
        "## Alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gssKpmIc6flK"
      },
      "source": [
        "# Images without defects are not included in the train.csv\n",
        "df = train.pivot(index='ImageId', columns='ClassId', values='EncodedPixels')\n",
        "df = df.merge(pd.DataFrame(index=os.listdir(train_image_path)), \n",
        "              left_index=True, \n",
        "              right_index=True, \n",
        "              how='right', \n",
        "              validate='one_to_one')\n",
        "\n",
        "df['num_defect'] = df.count(axis=1)\n",
        "df['num_defect'] = df['num_defect'].astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_CkK7TtD6flL",
        "outputId": "977694d5-5fd1-43d4-bf6c-fe63f32452c9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>num_defect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ea970bedf.jpg</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63939 1 64195 2 64451 5 64706 9 64962 11 65218...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eb4225311.jpg</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>303400 7 303654 15 303908 19 304163 19 304187 ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ec0e3a1c2.jpg</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>148340 2 148594 4 148848 6 149102 8 149357 9 1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eaf7443a7.jpg</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70658 255 70914 255 71170 255 71426 255 71682 ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ea7752e39.jpg</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 1    2  ...    4 num_defect\n",
              "ea970bedf.jpg  NaN  NaN  ...  NaN          1\n",
              "eb4225311.jpg  NaN  NaN  ...  NaN          1\n",
              "ec0e3a1c2.jpg  NaN  NaN  ...  NaN          1\n",
              "eaf7443a7.jpg  NaN  NaN  ...  NaN          1\n",
              "ea7752e39.jpg  NaN  NaN  ...  NaN          0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg3nIlqr6flL",
        "outputId": "0dc00a46-39ed-4bce-cd84-dac8616a2e29"
      },
      "source": [
        "df['num_defect'].value_counts().sort_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6345\n",
              "1    6239\n",
              "2     425\n",
              "3       2\n",
              "Name: num_defect, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez78PNE06flL"
      },
      "source": [
        "## Split to training/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IckzYMJF6flL",
        "outputId": "6775619d-435b-4d9a-d118-163236456013"
      },
      "source": [
        "train_df, valid_df = train_test_split(df, \n",
        "                                      test_size=0.2, \n",
        "                                      random_state=random_state, \n",
        "                                      shuffle=True, \n",
        "                                      stratify=df['num_defect'])\n",
        "train_df = train_df.drop(columns=['num_defect'])\n",
        "valid_df = valid_df.drop(columns=['num_defect'])\n",
        "train_df.shape, valid_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10408, 4), (2603, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO4jySF-6flM"
      },
      "source": [
        "train_id = [] # List of image id like 'xxx.jpg' for training set\n",
        "train_id.extend(train_df.index.to_list())\n",
        "train_id.extend([s.split('.')[0]+'_HF.jpg' for s in train_df.index])\n",
        "train_id.extend([s.split('.')[0]+'_VF.jpg' for s in train_df.index])\n",
        "train_id.extend([s.split('.')[0]+'_HVF.jpg' for s in train_df.index])\n",
        "\n",
        "# train_id = train_id[:16]\n",
        "valid_id = valid_df.index.to_list() # List of image id like 'xxx.jpg' for validation set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KnxJQwt6flM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472978d3-46b6-40d8-a4c3-5afdd8fa35b9"
      },
      "source": [
        "len(train_id), len(valid_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41632, 2603)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg8vbvve6flM"
      },
      "source": [
        "shuffle(train_id)\n",
        "# train_id[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqeOUASt6flN"
      },
      "source": [
        "def get_img_id(idx, img_id_list):\n",
        "    img_id = img_id_list[idx]\n",
        "    if '_' not in img_id:\n",
        "        img_id, augment = img_id, None\n",
        "    elif '_HF' in img_id: \n",
        "        img_id, augment = img_id.replace('_HF',''), 'HF'\n",
        "    elif '_VF' in img_id: \n",
        "        img_id, augment = img_id.replace('_VF',''), 'VF'\n",
        "    elif '_HVF' in img_id: \n",
        "        img_id, augment = img_id.replace('_HVF',''), 'HVF'\n",
        "    return img_id, augment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QBCfIxT6flN"
      },
      "source": [
        "## Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG8gD-qS6flN"
      },
      "source": [
        "# Define the pipeline for augmentation, Normalizing and totensor transform\n",
        "def take_trfm(mean, std, augment):\n",
        "    if not augment: \n",
        "        trfms = amt.Compose([amt.Normalize(mean=mean, std=std, p=1), \n",
        "                             ToTensorV2(transpose_mask=True)])\n",
        "    elif augment == 'HF': \n",
        "        trfms = amt.Compose([amt.HorizontalFlip(p=1), \n",
        "                             amt.Normalize(mean=mean, std=std, p=1), \n",
        "                             ToTensorV2(transpose_mask=True)])\n",
        "    elif augment == 'VF': \n",
        "        trfms = amt.Compose([amt.VerticalFlip(p=1), \n",
        "                             amt.Normalize(mean=mean, std=std, p=1), \n",
        "                             ToTensorV2(transpose_mask=True)])\n",
        "    elif augment == 'HVF': \n",
        "        trfms = amt.Compose([amt.HorizontalFlip(p=1), \n",
        "                             amt.VerticalFlip(p=1), \n",
        "                             amt.Normalize(mean=mean, std=std, p=1), \n",
        "                             ToTensorV2(transpose_mask=True)])\n",
        "    return trfms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtVRhDQF6flN"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRdu6tZh6flN"
      },
      "source": [
        "def get_mask(img_id, df):\n",
        "    \n",
        "    mask = np.zeros((256, 1600, 4))\n",
        "    defects = [] \n",
        "    \n",
        "    for i, label in enumerate(df.loc[img_id,:].to_list()):\n",
        "        if label is not np.nan: \n",
        "            label = [int(x) for x in label.split()]\n",
        "            pix_starts, pix_lengths = label[::2], label[1::2]\n",
        "            mask_ = np.zeros((256*1600, 1))\n",
        "            for start, length in zip(pix_starts, pix_lengths):\n",
        "                mask_[start:(start+length)] = 1\n",
        "            mask[:,:,i] = mask_.reshape((256, 1600), order='F') \n",
        "            defects.append(i+1)\n",
        "            \n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arHQb6p06flQ"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMHIbSGG6flR"
      },
      "source": [
        "## Map-style Dataset → DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "algDjjAN6flT"
      },
      "source": [
        "# Inherit torch.utils.data.Dataset and override '__getitem__' and '__len__'\n",
        "# Preprocessing \n",
        "class SteelDataset(Dataset):\n",
        "    def __init__(self, \n",
        "                 df, \n",
        "                 image_path, \n",
        "                 img_id_list, \n",
        "                 mean=(0.485, 0.456, 0.406), \n",
        "                 std=(0.229, 0.224, 0.225)):\n",
        "        self.df = df\n",
        "        self.image_path = image_path \n",
        "        self.img_id_list = img_id_list\n",
        "        self.mean = mean \n",
        "        self.std = std\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "        img_id, augment = get_img_id(idx, self.img_id_list)\n",
        "        img_path = os.path.join(self.image_path, img_id)\n",
        "        img = cv.imread(img_path)\n",
        "        mask = get_mask(img_id, self.df)\n",
        "        trfm = take_trfm(self.mean, self.std, augment)\n",
        "        amted = trfm(image=img, mask=mask)\n",
        "        img, mask = amted['image'], amted['mask'] \n",
        "        return img, mask\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img_id_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSJCu0M-6flT"
      },
      "source": [
        "train_dataset = SteelDataset(train_df, \n",
        "                             image_path=train_image_path, \n",
        "                             img_id_list=train_id)\n",
        "valid_dataset = SteelDataset(valid_df, \n",
        "                             image_path=train_image_path, \n",
        "                             img_id_list=valid_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCLJMV9_6flU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf7f731-5289-4225-c1ad-56504aa57533"
      },
      "source": [
        "len(train_dataset), len(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41632, 2603)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CygRLrIz6flU"
      },
      "source": [
        "batch_size = 8\n",
        "train_dataloader = DataLoader(train_dataset, \n",
        "                              batch_size=batch_size, \n",
        "                              shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, \n",
        "                              batch_size=batch_size, \n",
        "                              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOxSOTHa6flU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9610f3c2-8409-4f5f-c86a-182d2b9fa6a7"
      },
      "source": [
        "len(train_dataloader), len(valid_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5204, 326)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv4UHvcb6flU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a077dc45-fbd0-4f34-c6bd-8f4d61ef129b"
      },
      "source": [
        "for batch, (X, y) in enumerate(train_dataloader): \n",
        "    print(batch, X.shape, y.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([8, 3, 256, 1600]) torch.Size([8, 4, 256, 1600])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIVhWcKk6flV"
      },
      "source": [
        "## TensorData → DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLA1PCRo6flV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj_Qdn3R6flV"
      },
      "source": [
        "## ImageFolder → DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkA4xPCy6flV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXkjhGRz6flV"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ZHWioj6flV"
      },
      "source": [
        "# Sum of dice in a batch\n",
        "def cal_dice(output, mask_gt, threshold=0.5): \n",
        "    '''Calculate the dice of a batch (between ground truth mask and output tensor)'''\n",
        "    \n",
        "    batch_size = len(mask_gt)\n",
        "    prob = torch.sigmoid(output)\n",
        "#     mask_pred = (prob > threshold).astype('torch.uint8')\n",
        "    mask_pred = (prob > threshold).int()\n",
        "    \n",
        "    assert mask_gt.shape == mask_pred.shape \n",
        "    \n",
        "    mask_gt = mask_gt.reshape(shape=(batch_size, -1))\n",
        "    mask_pred = mask_pred.reshape(shape=(batch_size, -1))\n",
        "    \n",
        "    idx_neg = torch.nonzero(mask_gt.sum(-1)==0)\n",
        "    idx_pos = torch.nonzero(mask_gt.sum(-1)>=1)\n",
        "    \n",
        "    dice_neg = (mask_pred.sum(-1)==0).float()\n",
        "    dice_pos = 2 * (mask_gt * mask_pred).sum(-1) / (mask_gt + mask_pred).sum(-1)\n",
        "    \n",
        "    dice = torch.cat([dice_pos[idx_pos], dice_neg[idx_neg]])\n",
        "        \n",
        "#     dice = dice.numpy() # torch.tensor to numpy.ndarray\n",
        "#     dice = np.nanmean(dice) # Calculate the mean dice of a batch, ignore nan\n",
        "    \n",
        "    return dice.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9jCp5DY6flW"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCLyTjj66flW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2886e8-71db-4f0e-88db-8b5152f439a4"
      },
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5xm_RmS6flW"
      },
      "source": [
        "# state_file = \"../input/scores/model_state.pth\"\n",
        "# state_file = os.path.join(nb_path, \"model_state.pth\")\n",
        "# model = smp.Unet(encoder_name='resnet34', \n",
        "#                  encoder_weights='imagenet', \n",
        "#                  in_channels=3, \n",
        "#                  classes=4,)\n",
        "# if os.path.isfile(state_file):\n",
        "#     model.load_state_dict(torch.load(state_file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOeOppji6flX"
      },
      "source": [
        "## Visiualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghO9rw4j6flX"
      },
      "source": [
        "# model_path = 'C:/Users/ll/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth'\n",
        "# model_path = 'C:/Users/ll/.cache/torch/hub/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth'\n",
        "\n",
        "# torch.onnx.export(model, torch.rand(8, 3, 256, 1600), 'onnx_model.onnx') \n",
        "# torch.onnx.export(model_, torch.rand(8, 3, 256, 1600), 'onnx_model_.onnx')\n",
        "\n",
        "# netron.start('onnx_model.onnx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7IA0kdU6flY"
      },
      "source": [
        "# Train & Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUljdjFr6flY"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, batch_size=batch_size):\n",
        "    t0 = time.time()\n",
        "    size = len(dataloader.dataset) # Total number of images in dataset\n",
        "    n_batch = len(dataloader)\n",
        "    cum_loss, cum_dice = 0, 0\n",
        "    for batch, (X, y) in enumerate(dataloader): \n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        output = model(X)\n",
        "        loss = loss_fn(output, y)\n",
        "#         output = output.detach().cpu()\n",
        "#         y = y.detach().cpu()\n",
        "        dice = cal_dice(output, y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cum_loss = cum_loss + loss.item()\n",
        "        cum_dice = cum_dice + dice.item()\n",
        "        \n",
        "        if batch % 300 == 0:\n",
        "            t1 = time.time()\n",
        "            print(f'''Training Batch: {batch}/{n_batch}. \n",
        "                      Batch Loss: {loss.item():.4f}. \n",
        "                      Batch Dice: {dice.item()/batch_size:.4f}. \n",
        "                      Cost: {int(t1-t0)}s''') \n",
        "    \n",
        "    return cum_loss/size, cum_dice/size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVk3dhGW6flY"
      },
      "source": [
        "def validate(dataloader, model, loss_fn, batch_size=batch_size):\n",
        "    t0 = time.time()\n",
        "    size = len(dataloader.dataset)\n",
        "    n_batch = len(dataloader)\n",
        "    model.eval()\n",
        "    cum_loss, cum_dice = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader): \n",
        "            X, y = X.to(device), y.to(device)\n",
        "        \n",
        "            output = model(X)\n",
        "            loss = loss_fn(output, y)\n",
        "#             output = output.detach().cpu()\n",
        "#             y = y.detach().cpu()\n",
        "            dice = cal_dice(output, y) \n",
        "            \n",
        "            cum_loss = cum_loss + loss.item()\n",
        "            cum_dice = cum_dice + dice.item()\n",
        "\n",
        "            if batch % 30 == 0:\n",
        "                t1 = time.time()\n",
        "                print(f'''Validation Batch: {batch}/{n_batch}. \n",
        "                          Batch Loss: {loss.item():.4f}. \n",
        "                          Batch Dice: {dice.item()/batch_size:.4f}. \n",
        "                          Cost: {int(t1-t0)}s''') \n",
        "                \n",
        "    return cum_loss/size, cum_dice/size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKWSrFgL6flY"
      },
      "source": [
        "score_file = os.path.join(nb_path, \"scores.csv\")\n",
        "if os.path.isfile(score_file): \n",
        "    score_df = pd.read_csv(score_file, index_col=['epoch'])\n",
        "else:\n",
        "    score_df = pd.DataFrame(index=range(1,21), \n",
        "                            columns=['train_loss', 'train_dice', 'valid_loss', 'valid_dice'], \n",
        "                            dtype='float32')\n",
        "    score_df = score_df.rename_axis(mapper='epoch', axis='index')\n",
        "epoch_untrained = score_df[score_df['train_loss'].isna()].index.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8SOxMWL5u3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a4b6989-a854-45c4-9f33-89bc52575af0"
      },
      "source": [
        "f\"{min(epoch_untrained)-1} Epochs Trained.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'7 Epochs Trained.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__IeZmH56flZ",
        "outputId": "d214b1e2-3d52-49d9-ef92-275cf843b697"
      },
      "source": [
        "for t in tqdm(epoch_untrained[:1]):\n",
        "    \n",
        "    print(f\"Epoch {t} starts at {time.strftime('%H:%M:%S')}\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    # model_file = f\"../input/scores/model_trained_{t-1}.pth\"\n",
        "    model_file = os.path.join(nb_path, f\"model_trained_{t-1}.pth\")\n",
        "    assert os.path.isfile(model_file), \"No pretrained model!\"\n",
        "    model = torch.load(model_file)\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    train_loss, train_dice = train(train_dataloader, \n",
        "                                   model=model, \n",
        "                                   loss_fn=loss, \n",
        "                                   optimizer=optimizer) \n",
        "    valid_loss, valid_dice = validate(valid_dataloader, \n",
        "                                      model=model, \n",
        "                                      loss_fn=loss) \n",
        "    \n",
        "    score_df.loc[t,:] = [train_loss,train_dice,train_loss,valid_dice]\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    torch.save(model, os.path.join(nb_path, f\"model_trained_{t}.pth\")) \n",
        "    print(f\"Epoch {t} Model Saved!\")\n",
        "    torch.save(model.state_dict(), os.path.join(nb_path, f\"model_state_{t}.pth\"))\n",
        "    print(f\"Epoch {t} Model State Saved!\")\n",
        "    score_df.to_csv(os.path.join(nb_path, f\"scores.csv\"))\n",
        "    score_df.to_csv(os.path.join(nb_path, f\"scores_{t}.csv\"))\n",
        "    print(f\"Epoch {t} Scores Saved!\")\n",
        "\n",
        "    t1 = time.time()\n",
        "    print(f\"Epoch {t} ends at {time.strftime('%H:%M:%S')}. Total Cost: {(t1-t0)/60:.2f}min\")\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8\n",
            "Training Batch: 0/5204. Batch Loss: 0.0412, Batch Dice: 0.7710. Cost: 1.115208625793457s\n",
            "Training Batch: 300/5204. Batch Loss: 0.0065, Batch Dice: 0.7500. Cost: 290.69578528404236s\n",
            "Training Batch: 600/5204. Batch Loss: 0.0091, Batch Dice: 0.6778. Cost: 579.8312063217163s\n",
            "Training Batch: 900/5204. Batch Loss: 0.0103, Batch Dice: 0.8243. Cost: 868.5116031169891s\n",
            "Training Batch: 1200/5204. Batch Loss: 0.0128, Batch Dice: 0.6632. Cost: 1156.9396238327026s\n",
            "Training Batch: 1500/5204. Batch Loss: 0.0021, Batch Dice: 0.9184. Cost: 1445.0083475112915s\n",
            "Training Batch: 1800/5204. Batch Loss: 0.0048, Batch Dice: 0.8780. Cost: 1734.1638684272766s\n",
            "Training Batch: 2100/5204. Batch Loss: 0.0089, Batch Dice: 0.7672. Cost: 2022.1604435443878s\n",
            "Training Batch: 2400/5204. Batch Loss: 0.0225, Batch Dice: 0.7789. Cost: 2310.156712770462s\n",
            "Training Batch: 2700/5204. Batch Loss: 0.0055, Batch Dice: 0.7797. Cost: 2596.604157447815s\n",
            "Training Batch: 3000/5204. Batch Loss: 0.0038, Batch Dice: 0.8829. Cost: 2883.177857875824s\n",
            "Training Batch: 3300/5204. Batch Loss: 0.0180, Batch Dice: 0.7777. Cost: 3170.833858728409s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}